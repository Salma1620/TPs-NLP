{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7824686,"sourceType":"datasetVersion","datasetId":4584965}],"dockerImageVersionId":30664,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **extraire le texte**","metadata":{}},{"cell_type":"code","source":"from gensim.models import Word2Vec\nwith open(\"/kaggle/input/text-word2vec/text\", 'r') as file:\n    text_content = file.read()\n\nprint(text_content)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **tokenization**","metadata":{}},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize\ntokens = word_tokenize(text_content.lower())\nprint(tokens)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **model word2vec**","metadata":{}},{"cell_type":"code","source":"model = Word2Vec(sentences=[tokens], vector_size=100, window=5, min_count=1, workers=4)\nprint(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **representation vectorielle**","metadata":{}},{"cell_type":"code","source":"mot=\"morocco\"\nif mot in model.wv:\n    representation_vec = model.wv[mot]\n    print(f\"Représentation vectorielle de '{mot}': {representation_vec}\")\nelse:\n    print(f\"Le mot '{mot}' n'est pas dans le vocabulaire du modèle.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **similarite**","metadata":{}},{"cell_type":"code","source":"mot1=\"marrakech\"\nmot2=\"city\"\nif mot1 in model.wv and mot2 in model.wv:\n    similarite = model.wv.similarity(mot1, mot2)\n    print(f\"Similarité entre '{mot1}' et '{mot2}': {similarite}\")\nelse:\n    print(\"Assurez-vous que les deux mots sont dans le vocabulaire du modèle.\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **mots contextuels**","metadata":{}},{"cell_type":"code","source":"mot=\"morocco\"\nif mot in model.wv:\n    mots_contextuels = model.wv.most_similar(mot,topn=5)\n    print(f\"Mots contextuels les plus similaires pour '{mot}':\")\n    for mot, similarite in mots_contextuels:\n        print(f\"{mot}: {similarite}\")\nelse:\n    print(f\"Le mot '{mot_central}' n'est pas dans le vocabulaire du modèle.\")\n    \nprint(mots_contextuels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}